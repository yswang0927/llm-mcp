# Python å†…ç½®çš„å¼‚æ­¥ç¼–ç¨‹åº“ï¼Œè®© MCP å¯ä»¥éé˜»å¡åœ°æ‰§è¡Œä»»åŠ¡ï¼ˆæ¯”å¦‚èŠå¤©ã€æŸ¥è¯¢ï¼‰ã€‚
import asyncio
# è‡ªåŠ¨ç®¡ç†èµ„æºï¼Œç¡®ä¿ç¨‹åºé€€å‡ºæ—¶æ­£ç¡®å…³é—­ MCP è¿æ¥ã€‚
from contextlib import AsyncExitStack
import os
from openai import OpenAI
from dotenv import load_dotenv


"""
è¿™æ®µä»£ç èƒ½å¤Ÿåˆå§‹åŒ– MCP å®¢æˆ·ç«¯ï¼ˆä½†ä¸è¿æ¥æœåŠ¡å™¨ï¼‰ï¼Œå¹¶æä¾›ä¸€ä¸ª äº¤äº’å¼ CLIï¼Œ
å¹¶ä½¿ç”¨ OpenAI è¿æ¥åˆ°å¤§æ¨¡å‹ï¼Œ
é€šè¿‡è¾“å…¥ quit é€€å‡ºç¨‹åºã€‚

è¿è¡Œè¿™ä¸ªMCPå®¢æˆ·ç«¯ï¼š
uv run mcp-client.py
"""

# åŠ è½½ .env æ–‡ä»¶ï¼Œç¡®ä¿ API Key å—åˆ°ä¿æŠ¤
load_dotenv()

class MCPClient:
    def __init__(self):
        """åˆå§‹åŒ– MCP å®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  # è¯»å– OpenAI API Key
        self.base_url = os.getenv("BASE_URL")  # è¯»å– BASE YRL
        self.model = os.getenv("MODEL")  # è¯»å– model

        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")

        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)


    async def process_query(self, query: str) -> str:
        """è°ƒç”¨ OpenAI API å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å›ç­”é—®é¢˜ã€‚"},
                    {"role": "user", "content": query}]

        try:
            # è°ƒç”¨ OpenAI API
            # å› ä¸º OpenAI API æ˜¯åŒæ­¥çš„ï¼Œä½†æˆ‘ä»¬ç”¨çš„æ˜¯å¼‚æ­¥ä»£ç ï¼Œ
            # è¿™é‡Œç”¨ asyncio.get_event_loop().run_in_executor(...)
            # å°† OpenAI API å˜æˆå¼‚æ­¥ä»»åŠ¡ï¼Œé˜²æ­¢ç¨‹åºå¡é¡¿ã€‚
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=10000,
                    temperature=0.7 #æ§åˆ¶ AI å›ç­”çš„éšæœºæ€§ï¼ˆè¶Šé«˜è¶Šéšæœºï¼‰
                )
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âš ï¸ è°ƒç”¨ OpenAI API æ—¶å‡ºé”™: {str(e)}"


    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\nMCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")

        while True:
            try:
                query = input("\nQuery: ").strip()
                if query.lower() == 'quit':
                    break

                # å‘é€ç”¨æˆ·è¾“å…¥åˆ° OpenAI API
                response = await self.process_query(query)
                print(f"\nğŸ¤– OpenAI: {response}")

            except Exception as e:
                print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")


    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose()


async def main():
    client = MCPClient()
    try:
        await client.chat_loop() # å¯åŠ¨äº¤äº’å¼èŠå¤©
    finally:
        await client.cleanup() # ç¡®ä¿é€€å‡ºæ—¶æ¸…ç†èµ„æº

if __name__ == "__main__":
    asyncio.run(main())